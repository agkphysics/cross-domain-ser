rep,fold,fit_time,score_time,uar,war,microf1,macrof1,affection_rec,affection_prec,affection_f1,affection_ba,amusement_rec,amusement_prec,amusement_f1,amusement_ba,anger_rec,anger_prec,anger_f1,anger_ba,contempt_rec,contempt_prec,contempt_f1,contempt_ba,disgust_rec,disgust_prec,disgust_f1,disgust_ba,distress_rec,distress_prec,distress_f1,distress_ba,fear_rec,fear_prec,fear_f1,fear_ba,guilt_rec,guilt_prec,guilt_f1,guilt_ba,happiness_rec,happiness_prec,happiness_f1,happiness_ba,interest_rec,interest_prec,interest_f1,interest_ba,lust_rec,lust_prec,lust_f1,lust_ba,negativesurprise_rec,negativesurprise_prec,negativesurprise_f1,negativesurprise_ba,positivesurprise_rec,positivesurprise_prec,positivesurprise_f1,positivesurprise_ba,pride_rec,pride_prec,pride_f1,pride_ba,relief_rec,relief_prec,relief_f1,relief_ba,sadness_rec,sadness_prec,sadness_f1,sadness_ba,serenity_rec,serenity_prec,serenity_f1,serenity_ba,shame_rec,shame_prec,shame_f1,shame_ba,params,clf,features,corpus
0,0,2.2268837532028556,0.01601666072383523,0.08796296296296297,0.08796296296296297,0.08796296296296297,0.040642254453852,0.0,0.0,0.0,0.9416666666666667,0.0,0.0,0.0,0.9425925925925925,0.21666666666666667,0.40625,0.28260869565217395,0.9388888888888889,0.0,0.0,0.0,0.9444444444444444,0.016666666666666666,0.14285714285714285,0.029850746268656716,0.9398148148148148,0.0,0.0,0.0,0.9444444444444444,0.0,0.0,0.0,0.9435185185185185,0.75,0.05747126436781609,0.10676156583629894,0.30277777777777776,0.0,0.0,0.0,0.9444444444444444,0.0,0.0,0.0,0.9444444444444444,0.0,0.0,0.0,0.9444444444444444,0.0,0.0,0.0,0.9416666666666667,0.0,0.0,0.0,0.9444444444444444,0.0,0.0,0.0,0.9444444444444444,0.03333333333333333,0.4,0.06153846153846154,0.9435185185185185,0.0,0.0,0.0,0.9444444444444444,0.55,0.13636363636363635,0.21854304635761587,0.7814814814814814,0.016666666666666666,0.5,0.03225806451612903,0.9444444444444444,"{""C"": 1, ""class_weight"": null, ""dual"": false, ""fit_intercept"": true, ""intercept_scaling"": 1, ""l1_ratio"": null, ""max_iter"": 100, ""multi_class"": ""multinomial"", ""n_jobs"": null, ""penalty"": ""l2"", ""random_state"": null, ""solver"": ""lbfgs"", ""tol"": 0.0001, ""verbose"": 0, ""warm_start"": false}",sk/lr,wav2vec2_audeering_ft_c_mean,VENEC
